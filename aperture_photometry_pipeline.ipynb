{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aperture Photometry Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Description:</b> This pipeline is meant to be part of a three-step process for performing timing analysis on observations of a target time-variable object. The first step of the process was to reduce FITS files of the object by debiasing, dark-subtracting, and flat-fielding. For the pipeline corresponding to the first step, refer to <i>image_reduction_pipeline.ipynb</i>. The second step of the process is to perform aperture photometry on the reduced FITS files and extract the apparent magnitude(s) for the desired object(s). For the pipeline corresponding to the second step, refer to <i>aperture_photometry_pipeline.ipynb</i> (this file). The third step of this process is to perform the timing analysis on the extracted magnitudes themselves. For the pipeline corresponding to the third step, refer to <i>timing_analysis_pipeline.ipynb</i>.\n",
    "\n",
    "<b>This Jupyter Notebook file will perform the second step of this process: aperture photometry of the reduced FITS files</b>. It will take in the reduced FITS files and extract the apparent magnitudes of the object of observation as well as of any additional comparison stars (in our case, 5 comparison stars). \n",
    "\n",
    "<b>Directions:</b> You will need to manually feed in the initial x and y pixel coordinates of the object and comparison stars in the pipeline for the first image, but then the pipeline will automatically be able to find the x and y pixel coordinates of the objects for future frames. If the objects move a lot between frames, you have the option of specifying additional initial x and y coordinates that the pipeline can use to search for the object. <b>Note that the order in which in you input your list of initial coordinates matters</b>: the pipeline will use the first list of initial coordinates to search for your objects, and only when it fails to find the object will it move onto the next list of initial coordinates. There is no limit to the number of initial coordinates you can put into the pipeline. You will also need to manually input the directories in which the reduced FITS files are located. The pipeline will automatically subtract out the sky when performing aperture photometry, so you do not need to worry about that step, but it will NOT automatically debias, dark-subtract, or flat-field the images, so make sure you have done those three steps beforehand.\n",
    "<br>Sometimes the pipeline will still not find your object in spite of the initial coordinates you gave it. In this case, you may have to manually rimexam the object.\n",
    "\n",
    "<b>Output:</b> The output of the pipeline are a collection of text files, one for each directory that you fed into the pipeline. Each text file contains the x and y centroids of the objects, their aperture sum, their apparent magnitudes, the radius used for the aperture, the background sky value, the name of the object, and the FITS filename in which the flux was taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Run This File\n",
    "\n",
    "### The command line arguments to run this Python file is written below:\n",
    "#### python aperture_photometry_pipeline.py dir_proc_fits coord_file.txt offset=10 radius=5\n",
    "<ul>\n",
    "    <li>The first argument is the name of this python file (aperture_photometry_pipeline.py).\n",
    "    <li>The second argument is the PATH of the directory containing all your reduced fits files.\n",
    "    <li>The third argument is the name of the text file containing the initial coordinates of your object and comparison stars. This text file should be formatted as follows:\n",
    "<br><i>name1:(x,y)</i>\n",
    "<br><i>name2:(x,y)</i>\n",
    "<br><i>name3:(x,y)</i>\n",
    "        \n",
    "For example, if you think the object won't move too much in between frames, then the text file will look something like this:\n",
    "<br>A0620:(478, 565)\n",
    "<br>compstar1:(385, 535)\n",
    "<br>compstar2:(381, 475)\n",
    "<br>compstar3:(733,713)\n",
    "<br>compstar4:(557,286)\n",
    "<br>compstar5:(789,293)\n",
    "        \n",
    "But if you think the object WILL move a lot in between frames, then specify the second list of initial coordinates below the first, like this:\n",
    "<br>A0620:(478, 565)\n",
    "<br>compstar1:(385, 535)\n",
    "<br>compstar2:(381, 475)\n",
    "<br>compstar3:(733,713)\n",
    "<br>compstar4:(557,286)\n",
    "<br>compstar5:(789,293)\n",
    "<br>A0620:(498, 585)\n",
    "<br>compstar1:(405, 555)\n",
    "<br>compstar2:(401, 495)\n",
    "<br>compstar3:(753,733)\n",
    "<br>compstar4:(577,306)\n",
    "<br>compstar5:(809,313)\n",
    "<br>There is no limit to the number of initial coordinates you can put into the text file.\n",
    "    <li>The (optional) fourth argument is the maximum pixel movement of the objects between frames due to movement of the night sky and/or proper motion of the object that the pipeline should account for when searching for the object between frames. This is automatically set to 10, since this yielded the best results for previous A0620-00 data. \n",
    "<br><i>Note: a higher offset will decrease the accuracy of the pipeline finding the correct centroid of your objects as you move from frame to frame, since the pipeline searches in a wider area around the previous frame's centroid coordinates.</i>\n",
    "    <li>The (optional) fifth argument is the radius of the circular aperture to use when summing the flux around each object. This is automatically set to 5 since that's the previous radius we used in our existing A0620-00 data.\n",
    "</ul>\n",
    "\n",
    "### Assumptions Implicit in This Pipeline\n",
    "This pipeline assumes that the object and comparison stars don't overlap in the night sky with any other point sources, and that the fits files fed into the pipeline are already reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from astropy.io import fits\n",
    "from astropy.table import vstack, QTable\n",
    "from astropy.time import Time\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus, aperture_photometry\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Command Line Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for testing purposes\n",
    "#sys.argv[1] = \"test_dirs_Dec\\I-bess\"\n",
    "#sys.argv[2] = \"test_dirs_Dec\\I-bess\\Dec_coords_I.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a helper function that returns whether a file's extension is '.fits' or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_fits_file_extension(filename):\n",
    "    '''A function that returns whether a file's extension is '.fits' or not.'''\n",
    "    return filename.split(\".\")[-1] == \"fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the directory for the reduced fits files and the coordinate text file, and (optionally) the offset and radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sys.argv) == 1:\n",
    "    raise TypeError(\"aperture_photometry_pipeline.py missing two positional arguments: 'proc_files_dir', and 'coordinates.txt'\")\n",
    "if len(sys.argv) == 2:\n",
    "    raise TypeError(\"aperture_photometry_pipeline.py missing one positional argument: 'coordinates.txt'\")\n",
    "\n",
    "fits_path = sys.argv[1]\n",
    "fits_filenames = list(filter(has_fits_file_extension, os.listdir(fits_path)))\n",
    "coord_file = sys.argv[2]\n",
    "names = []\n",
    "starting_positions = []\n",
    "with open(coord_file, \"r+\") as file:\n",
    "    text = file.read()\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        name, coord = line.split(':')[0], line.split(':')[1]\n",
    "        xcor, ycor = int(float(coord.split(',')[0][1:])), int(float(coord.split(',')[1][:-1]))\n",
    "        if name in names:\n",
    "            starting_positions[names.index(name)].append([xcor, ycor])\n",
    "        else:\n",
    "            names.append(name)\n",
    "            starting_positions.append([[xcor, ycor]])\n",
    "starting_positions = np.array(starting_positions)\n",
    "\n",
    "offset = sys.argv[3] if len(sys.argv) > 3 else 10\n",
    "radius = sys.argv[4] if len(sys.argv) > 4 else 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the Apparent Magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(arr):\n",
    "    x_sum = 0\n",
    "    y_sum = 0\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(len(arr[i])):\n",
    "            x_sum += arr[i][j] * j\n",
    "            y_sum += arr[i][j] * i\n",
    "    x_com = x_sum / np.sum(arr)\n",
    "    y_com = y_sum / np.sum(arr)\n",
    "    return x_com, y_com\n",
    "\n",
    "def find_objects_stats(data, positions, file):\n",
    "    centroids = []\n",
    "    peaks = []\n",
    "    for i in range(len(positions)):\n",
    "        if positions[i][1] - offset < 0:\n",
    "            positions[i][1] = offset\n",
    "            print(positions[i][1])\n",
    "        elif positions[i][1] + offset >= len(data):\n",
    "            positions[i][1] = len(data) - offset - 1\n",
    "        elif positions[i][0] - offset < 0:\n",
    "            positions[i][0] = 0\n",
    "        elif positions[i][0] + offset >= len(data[0]):\n",
    "            positions[i][0] = len(data[0]) - offset - 1\n",
    "            \n",
    "        data_region = data[positions[i][1] - offset : positions[i][1] + offset, positions[i][0] - offset : positions[i][0] + offset] # Defining the area in which to look for object\n",
    "        xsub, ysub = centroid(data_region) # Finding centroid, but xsub and ysub have wrong index, so need to reindex\n",
    "        cen = (xsub + positions[i][0] - offset, ysub + positions[i][1] - offset) # reindexing\n",
    "        peak = data[int(cen[1])][int(cen[0])]\n",
    "        centroids.append(cen)\n",
    "        peaks.append(peak)\n",
    "    \n",
    "    # Finding the aperture sum of a circular region around each object and putting it into a QTable\n",
    "    aperture = CircularAperture(centroids, r=radius)\n",
    "    phot_table = aperture_photometry(data, aperture)\n",
    "    phot_table[\"xcenter\"] = phot_table[\"xcenter\"].value # Removing the unit quantity in xcenter and ycenter\n",
    "    phot_table[\"ycenter\"] = phot_table[\"ycenter\"].value\n",
    "    return phot_table, peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtains the apparent magnitudes of the object(s) and comparison stars, and then outputs them into an astropy QTable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a dummy table\n",
    "aperture_table = QTable({'xcenter': [], 'ycenter': [], 'aperture_sum': [], 'aperture_mag': [], 'R': [], 'sky': []})\n",
    "\n",
    "# Setting the initial position to search for the object(s) when finding centroids\n",
    "positions = starting_positions[:,0] # Gets the first element in every row\n",
    "starting_positions_index = 0\n",
    "\n",
    "# Routine to obtain the apparent magnitudes\n",
    "for file in fits_filenames:\n",
    "    # Opening the fits file\n",
    "    hdulist = fits.open(os.path.join(fits_path, file))\n",
    "    data_wsky = hdulist[0].data\n",
    "\n",
    "    # Subtracting out global sky background\n",
    "    skybkg = np.median(data_wsky)\n",
    "    data = data_wsky - skybkg\n",
    "    \n",
    "    # Finding centroid positions of A0620-00 and comparison stars using photutils.centroids package\n",
    "    phot_table, peaks = find_objects_stats(data, positions, file)\n",
    "    \n",
    "    # If aperture sum is negative, it most likely means the centroid has not been correctly found, most likely due to\n",
    "    #   extreme movement of the CCD camera and/or object in night sky, causing the coordinates of the object to shift\n",
    "    #   beyond the range of 'offset'. In this case, if we have another list of initial starting coordinates\n",
    "    #   in which to look for our objects, restart the centroid search with these coordinates; otherwise, continue as normal.\n",
    "    if any(i < 0 for i in phot_table[\"aperture_sum\"]):\n",
    "        starting_positions_index += 1\n",
    "        if starting_positions_index < len(starting_positions[0]):\n",
    "            positions = starting_positions[:,starting_positions_index]\n",
    "            phot_table, peaks = find_objects_stats(data, positions, file)\n",
    "    \n",
    "    # Finding the corresponding apparent magnitude and adding as a new column in the table. The flux and magnitude zeropoints were determined using curve_fits to previous A0620-00 data.\n",
    "    fluxzero = 10.91926955\n",
    "    magzero = 22.40441725\n",
    "    mag = -2.5*(np.log10(phot_table['aperture_sum'] / fluxzero)) + magzero\n",
    "    phot_table[\"aperture_mag\"] = mag\n",
    "    \n",
    "    # Finding the peak counts and adding it as a new column in the table.\n",
    "    phot_table[\"peak\"] = peaks\n",
    "    \n",
    "    # Adding name of the object, radius, background sky brightness, MJDs (modified Julian dates), exposure times, and filename as extra columns for future reference\n",
    "    phot_table['name'] = names\n",
    "    phot_table['R'] = [radius] * len(positions)\n",
    "    phot_table[\"sky\"] = [skybkg] * len(positions)\n",
    "    \n",
    "    UTCSTART = hdulist[0].header[\"UTCSTART\"]\n",
    "    MJD = Time(UTCSTART, format=\"isot\", scale=\"utc\").mjd\n",
    "    phot_table[\"MJD\"] = [MJD] * len(positions)\n",
    "    \n",
    "    exptime = hdulist[0].header[\"EXPTIME\"]\n",
    "    phot_table[\"exptime\"] = [exptime] * len(positions)\n",
    "    \n",
    "    phot_table[\"filename\"] = [file] * len(positions)\n",
    "    \n",
    "    # Cleaning up the column values to be easier to read\n",
    "    phot_table['xcenter'].info.format = '%.4g'\n",
    "    phot_table['ycenter'].info.format = '%.4g'\n",
    "    phot_table['aperture_sum'].info.format = '%.6g'\n",
    "    phot_table['aperture_mag'].info.format = '%.4g'\n",
    "    phot_table['sky'].info.format = '%.4g'\n",
    "    phot_table['peak'].info.format = '%.5g'\n",
    "    \n",
    "    # Appending the tables\n",
    "    aperture_table = vstack([aperture_table, phot_table])\n",
    "    \n",
    "    # Updating the position in which to base search for stars since objects move across night sky due to rotation of Earth\n",
    "    for i in range(len(phot_table[\"xcenter\"])):\n",
    "        positions[i] = [int(phot_table[\"xcenter\"][i]), int(phot_table[\"ycenter\"][i])]\n",
    "                \n",
    "    hdulist.close # Closing the fits file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the QTable out to a .escv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "aperture_table.write(os.path.join(fits_path,'logfile.ecsv'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the table within the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aperture_table # For testing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cells are for testing and debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes\n",
    "#mags_Apr = np.loadtxt(\"Dec 2020, Mar 2021, and Apr 2021 Dataset/logfile_April_data_only.txt\", usecols = 5, unpack=True)\n",
    "#flux_Apr = np.loadtxt(\"Dec 2020, Mar 2021, and Apr 2021 Dataset/logfile_April_data_only.txt\", usecols = 6, unpack=True)\n",
    "\n",
    "#plt.plot(range(len(mags_Apr)), aperture_table[\"aperture_mag\"] - mags_Apr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For testing purposes, used to determine flux and magnitude zeropoints\n",
    "#from scipy.optimize import curve_fit\n",
    "#def flux_to_mag(flux, fluxzero, magzero):\n",
    "#    mag = -2.5*np.log10(flux/fluxzero) + magzero\n",
    "#    return mag\n",
    "\n",
    "#parameters, covariance = curve_fit(flux_to_mag, flux_Apr, mags_Apr)\n",
    "#plt.plot(flux_Apr, mags_Apr, 'o', label='data')\n",
    "#fit_y = flux_to_mag(flux_Apr, parameters[0], parameters[1])\n",
    "#plt.plot(flux_Apr, fit_y, '.', label='fit')\n",
    "#plt.legend()\n",
    "#print(parameters, covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
